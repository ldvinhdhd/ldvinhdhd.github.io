<!DOCTYPE html>
<html>

      <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
        <title>The Visual Similarity of Movie Posters</title>
        <link rel="canonical" href="https://nathanrooy.github.io/posts/2019-03-24/movie-poster-tsne/">

        <!-- Meta (general) -->
        <meta name="author" content="Nathan Rooy">
        <meta name="copyright" content="Nathan A. Rooy">
        <meta name="description" content="100k movie posters + deep learning + tsne">
        <meta name="keywords" content="Python, tutorials, machine learning, deep learning, natural language processing, evolutionary optimization, urban design, mobility, geospatial analysis, data science, web scraping, Cincinnati">
        <meta name="language" content="en">
        <meta name="viewport" content="width=device-width">
        
        <!-- Meta (Twitter) -->
        <meta name="twitter:card" content="https://nathanrooy.github.io">
        <meta name="twitter:description" content="100k movie posters + deep learning + tsne">
        <meta name="twitter:title" content="The Visual Similarity of Movie Posters">
        <meta name="twitter:image" content="https://nathanrooy.github.io/images/2019-03-24/feature-image.jpg">
        
        <!-- Open Graph -->
        <meta property="og:description" content="100k movie posters + deep learning + tsne">
        <meta property="og:image" content="https://nathanrooy.github.io/images/2019-03-24/feature-image.jpg">
        <meta property="og:locale" content="en_US">
        <meta property="og:site_name" content="nathanrooy.github.io">
        <meta property="og:title" content="The Visual Similarity of Movie Posters">
        <meta property="og:type" content="article">
        <meta property="og:url" content="https://nathanrooy.github.io/posts/2019-03-24/movie-poster-tsne/">
        
        <!-- For all browsers -->
        <link rel="stylesheet" href="/assets/css/main.css">

        <!-- Favicon -->
        <link rel="shortcut icon" href="/favicon.png">
        
        <!-- GOOGLE ANALYTICS -->
        <script>
            (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
            (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
            m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
            })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

            ga('create', 'UA-88488688-1', 'auto');
            ga('send', 'pageview');
        </script>
        
        <!--- INCLUDE INLINE FOOTNOTES JAVASCRIPT -->
        <script src="/assets/js/inlineNotes.js"></script>
        
        <!--- MATHJAX --->
        <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
    </head>

    <body>

    <header id="site-header">
    <div class="wrap">
        <span>
            <h1>Nathan Rooy</h1>
            <hr size="10">
            <a href="/about/">About</a>
            <a href="mailto:nathanrooy@gmail.com?Subject=githubpage">Contact</a>
            <a href="/">Home</a>
        </span>
    </div>
</header>

    <div id="page-content">
      <div class="wrap">
      <div class="post">
    
    
    <header class="post-header">
        <h1>The Visual Similarity of Movie Posters</h1>
        <p class="post-meta">March 24, 2019</p>
    </header>
    
    
    <br>

    <article class="post-content">
        <p>Recently this past winter my friends and I were trying to find something to watch on one of the major video streaming services and as as usual, we were drowning in decision paralysis. Page after page, and still nothing. After a certain point, all the movie covers began to blend together at which point we gave up. This got me thinking on the visual similarity of movie posters and the seemingly unoriginal designs most of them have…</p>

<p>After doing a little research, it turns out that others have also noticed this pattern of visual similarity.<sup id="fnref:fn1"><a href="#fn:fn1" class="footnote">1</a></sup><sup>,</sup><sup id="fnref:fn2"><a href="#fn:fn2" class="footnote">2</a></sup><sup>,</sup><sup id="fnref:fn3"><a href="#fn:fn3" class="footnote">3</a></sup><sup>,</sup><sup id="fnref:fn4"><a href="#fn:fn4" class="footnote">4</a></sup> Within a short amount of time, I was able to come across dozens of common tropes movie studios have been using for their movie covers. Because all of the existing analysis had been manually completed, I began wondering if there was a way to automate that process and potentially find new visual relationships that hadn’t been noticed yet. Luckily, thanks to <a target="_blank" href="https://en.wikipedia.org/wiki/Deep_learning">deep learning</a>, this is a fairly trivial task.</p>

<p>Scraping the movie covers from the internet yielded just over 169k images, of which 2636 were identical duplicates and thus removed. From here, the pool of images was reduced by an additional ~5k because they were boring, algorithmically generated images. Utilizing <a target="_blank" href="https://github.com/tensorflow/tensorflow">TensorFlow</a> and the inceptionV3<sup id="fnref:fn5"><a href="#fn:fn5" class="footnote">5</a></sup> architecture pretrained on the <a target="_blank" href="https://en.wikipedia.org/wiki/ImageNet">ImageNet</a> dataset, I pulled network values from the second to last fully connected layer. This resulted in a 2048x1 vector which was then reduced down to a 2x1 using <a target="_blank" href="https://en.wikipedia.org/wiki/T-distributed_stochastic_neighbor_embedding">t-SNE</a>.<sup id="fnref:fn6"><a href="#fn:fn6" class="footnote">6</a></sup> Finally, the image vectors were translated from t-SNE space into a structured grid space via <a target="_blank" href="https://en.wikipedia.org/wiki/Combinatorial_optimization">combinatorial optimization</a> by solving the <a target="_blank" href="https://en.wikipedia.org/wiki/Assignment_problem">assignment problem</a>. The results as seen below, were then <a target="_blank" href="https://en.wikipedia.org/wiki/Tiled_web_map">tiled</a> and served through <a target="_blank" href="https://leafletjs.com/">Leaflet</a>. Make sure you click the full screen option!</p>

<link rel="stylesheet" href="/assets/leaflet/leaflet.css" />

<link href="https://ajax.googleapis.com/ajax/libs/jqueryui/1.10.4/themes/smoothness/jquery-ui.min.css" rel="stylesheet" type="text/css" />

<style type="text/css">
    #basemapslidercontainer {
      position: absolute;
      top: 50px;
      right: 10px;
      z-index: 1000;
    }
    #basemapslider{
      font-size:62.5%;
      margin: 14px;
      height: 125px;
      width:7px;
    }
    #map{
       width: 650px;
       height: 400px
    }
.leaflet-control-fullscreen a {
  background:#fff url(fullscreen.png) no-repeat 0 0;
  background-size:26px 52px;
  }
  .leaflet-touch .leaflet-control-fullscreen a {
    background-position: 2px 2px;
    }
  .leaflet-fullscreen-on .leaflet-control-fullscreen a {
    background-position:0 -26px;
    }
  .leaflet-touch.leaflet-fullscreen-on .leaflet-control-fullscreen a {
    background-position: 2px -24px;
    }
.leaflet-container {
	background-color:rgba(0,0,0,1);
}
/* Do not combine these two rules; IE will break. */
.leaflet-container:-webkit-full-screen {
  width:100%!important;
  height:100%!important;
  }
.leaflet-container.leaflet-fullscreen-on {
  width:100%!important;
  height:100%!important;
  }
.leaflet-pseudo-fullscreen {
  position:fixed!important;
  width:100%!important;
  height:100%!important;
  top:0!important;
  left:0!important;
  z-index:99999;
  }
@media
  (-webkit-min-device-pixel-ratio:2),
  (min-resolution:192dpi) {
    .leaflet-control-fullscreen a {
      background-image:url(fullscreen@2x.png);
    }
  }
</style>

<link href="/assets/leaflet/leaflet.fullscreen.css" rel="stylesheet" />

<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.0/jquery.min.js"></script>

<script src="https://ajax.googleapis.com/ajax/libs/jqueryui/1.10.4/jquery-ui.min.js"></script>

<script src="/assets/leaflet/leaflet.js"></script>

<script src="/assets/leaflet/Leaflet.fullscreen.min.js"></script>

<script src="/assets/leaflet/leaflet-hash.js"></script>

<script>
$(document).ready(function () {
var southWest = L.latLng(-80.25, -99.75),
    northEast = L.latLng(80.25, 99.75),
    bounds = L.latLngBounds(southWest, northEast);
var map = L.map('map').setView([0, 0], 3);
map.addControl(new L.Control.Fullscreen());
//map.setMaxBounds(map.getBounds());
map.setMaxBounds(bounds);
//map.fitBounds(group.getBounds());
var mytile =L.tileLayer('https://s3.amazonaws.com/movie-poster-tsne/iv3_avgpool_90292_tsnemc_plx30_manhattan_iter50000_lr10_rf90000_300x300_SUPER_TILE_2/tiles/{z}/{x}/{y}.jpg', {
maxBoundsViscosity:1,
maxZoom: 9,
minZoom: 2,
noWrap:true,
tms: true,
}).addTo(map);
console.log(map.getBounds().getSouthWest().toString());
console.log(map.getBounds().getNorthEast().toString());
console.log(map.getCenter());
console.log(map.getBounds().toString());
})
  </script>

<div id="map" style="margin-bottom:2em">
    <div id="basemapslidercontainer">
        <div id="basemapslider"></div>
    </div>
</div>

<p>Like the architecture of most neural networks tasked with image classification, the InceptionV3 is based around the <a target="_blank" href="https://en.wikipedia.org/wiki/Convolutional_neural_network">convolution</a>. Because of this, edges become the areas of interest within an image. While exploring the landscape, it’s interesting to note how sometimes the network is able to nail similarity while other times it’s questionable at best. This is partly because what we as humans define as similar can be quite different from what the network considers as similar. It’s also partly due to the fact that most movie posters are feature rich and T-SNE treats all positions within the feature vector fairly equal (i.e. trees == people == boats). Because of this, a movie poster with a forest with a single person is roughly equal to a poster with a couple of trees and multiple people. Either way, the network is able to produce some pretty interesting clusters.</p>

<h3>References</h3>

<div class="footnotes">
  <ol>
    <li id="fn:fn1">
      <p>Sidney Fussell, <a target="_blank" href="https://www.businessinsider.com/movie-poster-cliches-2016-5"><i>Hollywood keeps using these 13 movie poster clichés over and over again</i></a> (May 19, 2016) <a href="#fnref:fn1" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:fn2">
      <p>Christophe Courtois, <a target="_blank" href="https://afficheschristophecourtois.blogspot.com/2011/06/ces-affiches-me-sortent-par-les-yeux.html"><i>Ces affiches me sortent par les yeux!</i></a> (June 17, 2011) <a href="#fnref:fn2" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:fn3">
      <p>Christophe Courtois, <a target="_blank" href="https://afficheschristophecourtois.blogspot.com/2011/08/question-difficile-de-quelle-couleur.html"><i>Question difficile : de quelle couleur sont les robes dans les films?</i></a> (August 21, 2011) <a href="#fnref:fn3" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:fn4">
      <p>Christophe Courtois, <a target="_blank" href="https://afficheschristophecourtois.blogspot.com/2011/06/les-affiches-de-films-de-dos.html"><i>Les affiches de films… de dos</i></a> (June 21, 2011) <a href="#fnref:fn4" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:fn5">
      <p>C. Szegedy, V. Vanhoucke, S. Ioffe, J. Shlens, and Z. Wojna, <a target="_blank" href="https://arxiv.org/pdf/1512.00567v3.pdf"><i>Rethinking the Inception Architecture for Computer Vision</i></a> (Proceedings of the IEEE conference on computer vision and pattern recognition. 2016) <a href="#fnref:fn5" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:fn6">
      <p>L. Maaten, G. Hinton, <a target="_blank" href="https://lvdmaaten.github.io/publications/papers/JMLR_2008.pdf"><i>Visualizing Data using t-SNE</i></a> (Journal of Machine Learning Research 9, 2008) <a href="#fnref:fn6" class="reversefootnote">&#8617;</a></p>
    </li>
  </ol>
</div>

    </article>
    
    
    <!--- TAGS SECTION --->
    
    
    
    <!--- DIVIDING LINE -->
    
    <hr style="margin-top:-3em; margin-bottom:3em; height:1px; background-color:#d6d6d6; border:0;">
    
    
    <!-- POST TAGS -->
    <span class="tags" style="margin-bottom:4em; color:#808080;">TAGS:
    
    <a style="color:#808080" href="/tags/#deep learning">#deep learning</a>
    
    <a style="color:#808080" href="/tags/#t-sne">#t-sne</a>
    
    <a style="color:#808080" href="/tags/#python">#python</a>
    
    <a style="color:#808080" href="/tags/#tensorflow">#tensorflow</a>
    
    </span>

    <br>
    <br>
    <br>
    <br>
    
    
    
    <!--- END TAGS SECTION --->
    
</div>

      </div>
    </div>

    <footer class="site-footer">

<center>
    &copy; 2019  <a href="/about">Nathan A. Rooy</a>.
    <br>
    Built with <a target="_blank" href="http://jekyllrb.com" rel="nofollow">Jekyll</a>.
    Powered by <a target="_blank" href="http://www.github.com">GitHub</a>
    </center>
    
</footer>

    </body>
</html>
